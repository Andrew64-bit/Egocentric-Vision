{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\iplov\\miniconda3\\envs\\aml_ego\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib.colors import ListedColormap\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import subprocess\n",
    "import os\n",
    "from umap.umap_ import UMAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = [\n",
    "    \"get, take\",\n",
    "    \"place, place-on, place-back, put, put-back\",\n",
    "    \"open\",\n",
    "    \"close\",\n",
    "    \"clean, wipe-off, wipe, wash, rinse\",\n",
    "    \"cut, chop, slice\",\n",
    "    \"mix, mix-around, stir, whisk\",\n",
    "    \"pour\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:   \n",
    "\n",
    "    # Assicurati di essere nella directory corretta\n",
    "    os.chdir(\"C:/Users/iplov/Desktop/Advanced ML/Progetto/github andrew/Egocentric-Vision\")\n",
    "    # Comando da eseguire\n",
    "    command = [\n",
    "        'python', 'save_feat.py',\n",
    "        'config=configs/I3D_save_feat.yaml',\n",
    "        'dataset.shift=D1-D1',\n",
    "        'dataset.RGB.data_path=D:/ek_data/frames',\n",
    "        'save.dense_sampling.RGB=true',\n",
    "        'save.num_frames_per_clip.RGB=5',\n",
    "        'name=saved_feat_I3D_5_Dense'\n",
    "    ]\n",
    "\n",
    "    # Esegui il comando\n",
    "    result = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "    # Stampa l'output e l'errore\n",
    "    print('Output:', result.stdout)\n",
    "    #print('Error:', result.stderr)\n",
    "\n",
    "    # Verifica il codice di uscita\n",
    "    if result.returncode != 0:\n",
    "        print(f'Command failed with return code {result.returncode}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assicurati di essere nella directory corretta\n",
    "os.chdir(\"C:/Users/iplov/Desktop/Advanced ML/Progetto/github andrew/Egocentric-Vision\")\n",
    "num_frames_list = [5,10,25]\n",
    "#DENSE\n",
    "if False:\n",
    "    for n in num_frames_list:\n",
    "        # Comando da eseguire\n",
    "        command = [\n",
    "            'python', 'save_feat.py',\n",
    "            'config=configs/I3D_save_feat.yaml',\n",
    "            'dataset.shift=D1-D1',\n",
    "            'dataset.RGB.data_path=D:/ek_data/frames',\n",
    "            'save.dense_sampling.RGB=true',\n",
    "            f'save.num_frames_per_clip.RGB={n}',\n",
    "            f'name=saved_feat_I3D_{n}_dense'\n",
    "        ]\n",
    "\n",
    "        # Esegui il comando\n",
    "        result = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "        # Stampa l'output e l'errore\n",
    "        print('Output:', result.stdout)\n",
    "        #print('Error:', result.stderr)\n",
    "\n",
    "        # Verifica il codice di uscita\n",
    "        if result.returncode != 0:\n",
    "            print(f'Command failed with return code {result.returncode}')\n",
    "\n",
    "    #UNIFORM\n",
    "    for n in num_frames_list:\n",
    "        print(f\"UNIFORM n = {n}\")\n",
    "        # Comando da eseguire\n",
    "        command = [\n",
    "            'python', 'save_feat.py',\n",
    "            'config=configs/I3D_save_feat.yaml',\n",
    "            'dataset.shift=D1-D1',\n",
    "            'dataset.RGB.data_path=D:/ek_data/frames',\n",
    "            'save.dense_sampling.RGB=false',\n",
    "            f'save.num_frames_per_clip.RGB={n}',\n",
    "            f'name=saved_feat_I3D_{n}_uniform'\n",
    "        ]\n",
    "\n",
    "        # Esegui il comando\n",
    "        result = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "        # Stampa l'output e l'errore\n",
    "        print('Output:', result.stdout)\n",
    "        #print('Error:', result.stderr)\n",
    "\n",
    "        # Verifica il codice di uscita\n",
    "        if result.returncode != 0:\n",
    "            print(f'Command failed with return code {result.returncode}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract train feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assicurati di essere nella directory corretta\n",
    "os.chdir(\"/Users/andreavannozzi/GithubProjects/Egocentric-Vision\")\n",
    "num_frames_list = [5,10,25]\n",
    "#DENSE\n",
    "if True:\n",
    "    for n in num_frames_list:\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"UNIFORM n = {n}\")\n",
    "        # Comando da eseguire\n",
    "        command = [\n",
    "            'python', 'save_feat.py',\n",
    "            'config=configs/I3D_save_feat.yaml',\n",
    "            'dataset.shift=D1-D1',\n",
    "            'dataset.RGB.data_path=./ek_data/frames',\n",
    "            'save.dense_sampling.RGB=false',\n",
    "            f'save.num_frames_per_clip.RGB={n}',\n",
    "            f'name=saved_feat_I3D_{n}_uniform',\n",
    "            'split=train'\n",
    "        ]\n",
    "\n",
    "        # Esegui il comando\n",
    "        result = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "        # Stampa l'output e l'errore\n",
    "        print('Output:', result.stdout)\n",
    "        print('Error:', result.stderr)\n",
    "\n",
    "        # Verifica il codice di uscita\n",
    "        if result.returncode != 0:\n",
    "            print(f'Command failed with return code {result.returncode}')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read extracted feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_pickle(\"./saved_features/saved_feat_I3D_10_dense_D1_test.pkl\")\n",
    "#print(features['features'][0])\n",
    "print(len(features['features']))\n",
    "#print(features['features'][0]['features_RGB'])\n",
    "#print(features['features'][0]['label'])\n",
    "print(features['features'][0].keys())\n",
    "list_of_features = [np.mean(np.array(feature['features_RGB']),axis=0) for feature in features[\"features\"]]\n",
    "clips_feature = list_of_features\n",
    "labels = [feature['label'] for feature in features[\"features\"]]\n",
    "labels_extended = [label for label in labels for _ in range(5)]\n",
    "print(labels_extended[0:20])\n",
    "list_of_features = [np.array(f) for feature in features[\"features\"] for f in feature['features_RGB']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_pickle(\"./train_val/D1_test.pkl\")\n",
    "#print(features['features'][0])\n",
    "print(features.keys())\n",
    "print(len(features))\n",
    "#print(features['features'][0]['features_RGB'])\n",
    "#print(features['features'][0]['label'])\n",
    "\n",
    "print(len(set(features['verb'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clips_feature_tensor = np.array(clips_feature)\n",
    "\n",
    "print(clips_feature_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot using TSNE 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot k-means labels\n",
    "kmeans = KMeans(n_clusters=8, random_state=0, n_init=\"auto\").fit(clips_feature_tensor)\n",
    "cmap = ListedColormap(['blue', 'orange', 'green', 'red', 'purple', 'gray', 'black', 'olive'])\n",
    "\n",
    "y_kmeans = kmeans.predict(clips_feature_tensor)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "# Addestrare il modello e trasformare i dati\n",
    "X = tsne.fit_transform(clips_feature_tensor)\n",
    "# scatter plot of X values\n",
    "plt.figure(1)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans,cmap=cmap, s=50)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#plot real labels\n",
    "cmap = ListedColormap(['gray', 'orange', 'black', 'red', 'green', 'olive', 'purple', 'blue'])\n",
    "legend_handles = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=cmap(i),  markersize=10, label=desc) \n",
    "                for i, desc in enumerate(LABELS)]\n",
    "plt.figure(2)\n",
    "\n",
    "# scatter plot of X values\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels, cmap=cmap, s=50)\n",
    "# Add the legend\n",
    "plt.legend(handles=legend_handles, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot using TSNE 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=8, random_state=0, n_init=\"auto\").fit(clips_feature_tensor)\n",
    "cmap = ['blue', 'orange', 'green', 'red', 'purple', 'gray', 'black', 'olive']\n",
    "kmeans_color_map = {f\"{i}\": color for i, color in enumerate(cmap)}\n",
    "\n",
    "y_kmeans = kmeans.predict(clips_feature_tensor)\n",
    "\n",
    "tsne = TSNE(n_components=3, random_state=42)\n",
    "# Addestrare il modello e trasformare i dati\n",
    "X = tsne.fit_transform(clips_feature_tensor)\n",
    "# scatter plot of X values\n",
    "df = pd.DataFrame(X, columns=['x', 'y', 'z'])\n",
    "df['kmeans'] = y_kmeans.astype(str)\n",
    "df['labels'] = np.array(labels).astype(str)\n",
    "\n",
    "\n",
    "#plot label k_means\n",
    "fig = px.scatter_3d(df, x='x', y='y', z='z', color=\"kmeans\", color_discrete_map=kmeans_color_map, title=\"plot using k_means label\")\n",
    "fig.update_traces(marker_size=4)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "cmap = ['blue', 'orange', 'black', 'red', 'green', 'olive', 'purple', 'gray']\n",
    "#plot real label\n",
    "fig = go.Figure()\n",
    "for i, label in enumerate(LABELS):\n",
    "    class_data = df[df['labels'] == str(i)]\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=class_data['x'], y=class_data['y'], z=class_data['z'],\n",
    "        mode='markers',\n",
    "        marker=dict(size=10, color=cmap[i]),\n",
    "        name=label\n",
    "    ))\n",
    "fig.update_traces(marker_size=4)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UMAP 2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_2d = UMAP(n_components=2, init='random', random_state=0)\n",
    "proj_2d = umap_2d.fit_transform(clips_feature_tensor)\n",
    "\n",
    "\n",
    "#plot k-means labels\n",
    "kmeans = KMeans(n_clusters=8, random_state=0, n_init=\"auto\").fit(clips_feature_tensor)\n",
    "cmap = ListedColormap(['blue', 'orange', 'green', 'red', 'purple', 'gray', 'black', 'olive'])\n",
    "\n",
    "y_kmeans = kmeans.predict(clips_feature_tensor)\n",
    "\n",
    "# scatter plot of X values\n",
    "plt.figure(1)\n",
    "plt.scatter(proj_2d[:, 0], proj_2d[:, 1], c=y_kmeans,cmap=cmap, s=50)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#plot real labels\n",
    "cmap = ListedColormap(['gray', 'orange', 'black', 'red', 'green', 'olive', 'purple', 'blue'])\n",
    "legend_handles = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=cmap(i),  markersize=10, label=desc) \n",
    "                for i, desc in enumerate(LABELS)]\n",
    "plt.figure(2)\n",
    "\n",
    "# scatter plot of X values\n",
    "plt.scatter(proj_2d[:, 0], proj_2d[:, 1], c=labels, cmap=cmap, s=50)\n",
    "# Add the legend\n",
    "plt.legend(handles=legend_handles, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UMAP 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = ['blue', 'orange', 'green', 'red', 'purple', 'gray', 'black', 'olive']\n",
    "color_map = {f\"{i}\": color for i, color in enumerate(cmap)}\n",
    "\n",
    "umap_3d = UMAP(n_components=3, init='random', random_state=0)\n",
    "proj_3d = umap_3d.fit_transform(clips_feature_tensor)\n",
    "\n",
    "df3d = pd.DataFrame(proj_3d, columns=['x', 'y', 'z'])\n",
    "df3d['kmeans'] = y_kmeans.astype(str)\n",
    "df3d['labels'] = np.array(labels).astype(str)\n",
    "\n",
    "#plot kmeans\n",
    "fig_3d = px.scatter_3d(\n",
    "    df3d, x='x', y='y', z='z',\n",
    "    color='kmeans', color_discrete_map=color_map\n",
    ")\n",
    "fig_3d.update_traces(marker_size=5)\n",
    "fig_3d.show()\n",
    "\n",
    "\n",
    "cmap = ['blue', 'orange', 'black', 'red', 'green', 'gray', 'purple', 'olive']\n",
    "kmeans_color_map = {f\"{i}\": color for i, color in enumerate(cmap)}\n",
    "custom_legend = {f\"{i}\": label_name for i, label_name in enumerate(LABELS)}\n",
    "#plot real label\n",
    "fig = go.Figure()\n",
    "for i, label in enumerate(LABELS):\n",
    "    class_data = df3d[df3d['labels'] == str(i)]\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=class_data['x'], y=class_data['y'], z=class_data['z'],\n",
    "        mode='markers',\n",
    "        marker=dict(size=10, color=cmap[i]),\n",
    "        name=label\n",
    "    ))\n",
    "fig.update_traces(marker_size=5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read actionet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'file', 'description', 'labels'], dtype='object')\n",
      "527\n",
      "2\n",
      "[39, 51]\n",
      "2\n",
      "2\n",
      "file train: ['S00_2.pkl', 'S01_1.pkl', 'S02_2.pkl', 'S02_3.pkl', 'S02_4.pkl', 'S03_1.pkl', 'S03_2.pkl', 'S04_1.pkl', 'S05_2.pkl', 'S06_1.pkl', 'S06_2.pkl', 'S07_1.pkl', 'S08_1.pkl', 'S09_2.pkl']\n",
      "file test: ['S00_2.pkl', 'S02_2.pkl', 'S02_3.pkl', 'S03_1.pkl', 'S03_2.pkl', 'S04_1.pkl', 'S05_2.pkl', 'S06_1.pkl', 'S06_2.pkl', 'S07_1.pkl', 'S08_1.pkl', 'S09_2.pkl']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>file</th>\n",
       "      <th>description</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>S00_2.pkl</td>\n",
       "      <td>Clean a plate with a towel</td>\n",
       "      <td>Clean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>S00_2.pkl</td>\n",
       "      <td>Unload dishwasher: 3 each large/small plates, ...</td>\n",
       "      <td>Unload</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index       file                                        description  \\\n",
       "40     40  S00_2.pkl                         Clean a plate with a towel   \n",
       "52     52  S00_2.pkl  Unload dishwasher: 3 each large/small plates, ...   \n",
       "\n",
       "    labels  \n",
       "40   Clean  \n",
       "52  Unload  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features1 = pd.read_pickle(\"./action-net/ActionNet_train.pkl\")\n",
    "features2 = pd.read_pickle(\"./action-net/ActionNet_test.pkl\")\n",
    "#print(features['features'][0])\n",
    "print(features1.keys())\n",
    "print(len(features1))\n",
    "#print(features['features'][0]['features_RGB'])\n",
    "#print(features['features'][0]['label'])\n",
    "l = list(zip(features1['index'][:],features1['file'][:],features1['description'][:],features1['labels'][:]))\n",
    "for el in l:\n",
    "    pass\n",
    "    #print(el)\n",
    "#print(len(set(features['description'])))\n",
    "#print(sorted(set(features['description'])))\n",
    "\n",
    "s04 = features2[features2['file'] == 'S00_2.pkl']\n",
    "print(len(set(s04['index'])))\n",
    "print(sorted(np.array(s04['index']) - 1))\n",
    "print(len(set(s04['index'])))\n",
    "print(len(list(s04['index'])))\n",
    "print(f\"file train: {sorted(set(features1['file']))}\")\n",
    "print(f\"file test: {sorted(set(features2['file']))}\")\n",
    "s04\n",
    "#['Clean a pan with a sponge', 'Clean a pan with a towel', 'Clean a plate with a sponge', 'Clean a plate with a towel', 'Clear cutting board', 'Get items from cabinets: 3 each large/small plates, bowls, mugs, glasses, sets of utensils', 'Get items from refrigerator/cabinets/drawers', 'Get/replace items from refrigerator/cabinets/drawers', 'Load dishwasher: 3 each large/small plates, bowls, mugs, glasses, sets of utensils', 'Open a jar of almond butter', 'Open/close a jar of almond butter', 'Peel a cucumber', 'Peel a potato', 'Pour water from a pitcher into a glass', 'Set table: 3 each large/small plates, bowls, mugs, glasses, sets of utensils', 'Slice a cucumber', 'Slice a potato', 'Slice bread', 'Spread almond butter on a bread slice', 'Spread jelly on a bread slice', 'Stack on table: 3 each large/small plates, bowls', 'Unload dishwasher: 3 each large/small plates, bowls, mugs, glasses, sets of utensils']\n",
    "#['Clean a pan with a towel', 'Clean a plate with a sponge', 'Clean a plate with a towel', 'Clear cutting board', 'Get items from cabinets: 3 each large/small plates, bowls, mugs, glasses, sets of utensils', 'Get items from refrigerator/cabinets/drawers', 'Get/replace items from refrigerator/cabinets/drawers', 'Load dishwasher: 3 each large/small plates, bowls, mugs, glasses, sets of utensils', 'Open/close a jar of almond butter', 'Peel a cucumber', 'Peel a potato', 'Pour water from a pitcher into a glass', 'Set table: 3 each large/small plates, bowls, mugs, glasses, sets of utensils', 'Slice a cucumber', 'Slice a potato', 'Slice bread', 'Spread almond butter on a bread slice', 'Spread jelly on a bread slice', 'Stack on table: 3 each large/small plates, bowls', 'Unload dishwasher: 3 each large/small plates, bowls, mugs, glasses, sets of utensils']\n",
    "\n",
    "#robe simili \"open a jar of almond butter\" == \"open/close a jar of almond butter\" &&&\n",
    "#            \"Get items from refrigerator/cabinets/drawers\" == \"Get/replace items from refrigerator/cabinets/drawers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = 'D:/ActionNetDataset/2022-06-07_18-11-37_streamLog_actionNet-wearables_S04_1.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:/ActionNetDataset/2022-06-07_18-11-37_streamLog_actionNet-wearables_S04_1.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Apri il file HDF5 in modalità lettura\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m hdf:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Stampa il contenuto del file HDF5\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeys: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m hdf\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m     12\u001b[0m     emg_left_data \u001b[38;5;241m=\u001b[39m hdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmyo-left\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memg\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][:]\n",
      "File \u001b[1;32mc:\\Users\\iplov\\miniconda3\\envs\\aml_ego\\Lib\\site-packages\\h5py\\_hl\\files.py:562\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    553\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    554\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    555\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[0;32m    556\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[0;32m    557\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[0;32m    558\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    559\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[0;32m    560\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[0;32m    561\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 562\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[1;32mc:\\Users\\iplov\\miniconda3\\envs\\aml_ego\\Lib\\site-packages\\h5py\\_hl\\files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[0;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = 'D:/ActionNetDataset/2022-06-07_18-11-37_streamLog_actionNet-wearables_S04_1.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Specifica il percorso del file HDF5\n",
    "file_path = r\"D:/ActionNetDataset/2022-06-07_18-11-37_streamLog_actionNet-wearables_S04_1.hdf5\"\n",
    "\n",
    "# Apri il file HDF5 in modalità lettura\n",
    "with h5py.File(file_path, 'r') as hdf:\n",
    "    # Stampa il contenuto del file HDF5\n",
    "    print(\"Keys: %s\" % hdf.keys())\n",
    "\n",
    "    emg_left_data = hdf['myo-left']['emg']['data'][:]\n",
    "    emg_left_time = hdf['myo-left']['emg']['time_s'][:]\n",
    "    \n",
    "    emg_right_data = hdf['myo-right']['emg']['data'][:]\n",
    "    emg_right_time = hdf['myo-right']['emg']['time_s'][:]\n",
    "    #print(len(emg_left_data))\n",
    "    #print(len(emg_right_data))\n",
    "    print(hdf['eye-tracking-video-world']['frame_timestamp']['time_str'][0])  ## USA QUESTO PER I FRAME RGB\n",
    "    print(hdf['eye-tracking-video-world']['frame_timestamp']['time_str'][-1])\n",
    "    print(hdf['eye-tracking-video-world']['frame_timestamp']['time_s'][-1] - hdf['eye-tracking-video-world']['frame_timestamp']['time_s'][0])\n",
    "\n",
    "    '''\n",
    "    activities = [[x.decode('utf-8') for x in row] for row in hdf['experiment-activities']['activities']['data']]\n",
    "    \n",
    "    datasetsx = hdf['myo-left']\n",
    "    datasetdx = hdf['myo-right']\n",
    "\n",
    "    print(len(datasetsx['emg']['data']))\n",
    "    #data_sx = datasetsx[:]\n",
    "    #data_dx = datasetdx[:]\n",
    "\n",
    "    # Stampa i dati (o fai altre operazioni con i dati)\n",
    "    print(\"---------------Data from 'myo-left':\")\n",
    "    print(datasetsx.keys())\n",
    "    print(datasetsx['emg'].keys())\n",
    "    print(datasetsx['emg']['data'][0])\n",
    "\n",
    "#    print(\"Data from 'myo-right':\")\n",
    "#    print(datasetdx.keys())\n",
    "    \n",
    "\n",
    "    # Replace with your path to one of the subjects from Action-Net\n",
    "    #emg_annotations = pd.read_pickle(\"../../aml22-ego-solutions/action-net/emg_annotations/S04_1.pkl\")\n",
    "    dataset_emgSX = datasetsx['emg']\n",
    "    sample_no = 1\n",
    "    signal = torch.from_numpy(dataset_emgSX['data'][:]).float()\n",
    "    title = 'myo-left emg signal'\n",
    "    print(dataset_emgSX['time_str'][137552:137560])\n",
    "    #compute_spectrogram(signal, title)\n",
    "    print(f\"FIRST DATA -----> data: {dataset_emgSX['data'][137552]} ,time: {dataset_emgSX['time_str'][137552]}, time_s_original: {dataset_emgSX['time_s_original'][137552]}, time_s: {dataset_emgSX['time_s'][137552]}\")\n",
    "    dataLabel = hdf['experiment-activities']['activities']\n",
    "    print(\"---------------Data from 'experiment-activities':\")\n",
    "    print(dataLabel.keys())\n",
    "    print(dataLabel['data'].shape)\n",
    "    print(dataLabel['data'][0:2][:])\n",
    "    sett = set()\n",
    "    for (l,s,v,n) in dataLabel['data']:\n",
    "        sett.add(n)\n",
    "    \n",
    "    for n in sett:\n",
    "        print(n)\n",
    "    \n",
    "    print(\"---------------time_str-----------------:\")\n",
    "    print(dataLabel['time_str'][0:2])\n",
    "    print(dataLabel['time_s'][1] - dataLabel['time_s'][0])\n",
    "    print(\"---------------Data from 'experiment-notes':\")\n",
    "    dataLabel = hdf['experiment-notes']\n",
    "    print(dataLabel.keys())\n",
    "    print(dataLabel['notes']['data'][:,:])\n",
    "    \n",
    "\n",
    "    \n",
    "    datasetsx = hdf['myo-left']['emg']\n",
    "    print(datasetsx.keys())\n",
    "    left_time_set = list(np.round(hdf['myo-left']['emg']['time_s'], 2))\n",
    "    left_idx_set = set()\n",
    "    for (i,el) in enumerate(list(np.round(hdf['myo-right']['emg']['time_s'], 2))):\n",
    "        if el in left_time_set:\n",
    "            left_index = left_time_set.index(el)\n",
    "            left_idx_set.add(left_index)\n",
    "            #print(f\"Match! i: {i}, el: {el}, left_index: {left_index}\")\n",
    "        if i%3000 == 0 and i == 0:\n",
    "            print(f\"i: {i}, el: {el}\")\n",
    "            break\n",
    "    for e in left_idx_set:\n",
    "        print(f\"left idx: {e}\")\n",
    "    print(f\"-----------\\n{len(left_idx_set)}\\n------------\")\n",
    "    print(hdf['myo-right']['emg']['time_str'][-1])\n",
    "    print(len(hdf['eye-tracking-video-eye']['frame_timestamp']['time_str']))\n",
    "    print(hdf['eye-tracking-video-eye']['frame_timestamp']['time_str'][0])\n",
    "    print(hdf['eye-tracking-video-eye']['frame_timestamp']['time_str'][-1])\n",
    "    print(len(hdf['eye-tracking-video-world']['frame_timestamp']['time_str']))\n",
    "    print(hdf['eye-tracking-video-world']['frame_timestamp']['time_str'][0])  ## USA QUESTO PER I FRAME RGB\n",
    "    print(hdf['eye-tracking-video-world']['frame_timestamp']['time_str'][-1])\n",
    "    print(hdf['eye-tracking-video-world']['frame_timestamp']['time_s'][108768] - hdf['eye-tracking-video-world']['frame_timestamp']['time_s'][0])\n",
    "# Crea DataFrame per i dati della mano sinistra e destra\n",
    "# Aggiungi i canali come colonne separate\n",
    "df_left = pd.DataFrame(emg_left_data, columns=[f'emg_left_ch{i+1}' for i in range(emg_left_data.shape[1])])\n",
    "df_left['time_s'] = emg_left_time\n",
    "\n",
    "df_right = pd.DataFrame(emg_right_data, columns=[f'emg_right_ch{i+1}' for i in range(emg_right_data.shape[1])])\n",
    "df_right['time_s'] = emg_right_time\n",
    "\n",
    "# Unisci i DataFrame sui timestamp\n",
    "merged_df = pd.merge_asof(df_left.sort_values('time_s'), df_right.sort_values('time_s'), on='time_s', direction='nearest')'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract EMG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: \n",
      "Error: \n",
      "Successfully processed 2022-06-14_16-38-43_streamLog_actionNet-wearables_S04_1.hdf5\n",
      "file = S04_1.pkl\n",
      "\n",
      "Output: \n",
      "Error: \n",
      "Successfully processed 2022-06-13_18-14-59_streamLog_actionNet-wearables_S01_1.hdf5\n",
      "file = S01_1.pkl\n",
      "\n",
      "Output: \n",
      "Error: \n",
      "Successfully processed 2022-06-13_22-35-11_streamLog_actionNet-wearables_S02_3.hdf5\n",
      "file = S02_3.pkl\n",
      "\n",
      "Output: \n",
      "Error: \n",
      "Successfully processed 2022-06-13_23-22-44_streamLog_actionNet-wearables_S02_4.hdf5\n",
      "file = S02_4.pkl\n",
      "\n",
      "Output: \n",
      "Error: \n",
      "Successfully processed 2022-06-14_13-12-07_streamLog_actionNet-wearables_S03_1.hdf5\n",
      "file = S03_1.pkl\n",
      "\n",
      "Output: \n",
      "Error: \n",
      "Successfully processed 2022-06-14_13-52-57_streamLog_actionNet-wearables_S03_2.hdf5\n",
      "file = S03_2.pkl\n",
      "\n",
      "Output: \n",
      "Error: \n",
      "Successfully processed 2022-06-14_20-46-12_streamLog_actionNet-wearables_S05_2.hdf5\n",
      "file = S05_2.pkl\n",
      "\n",
      "Output: \n",
      "Error: \n",
      "Successfully processed 2022-07-12_14-31-04_streamLog_actionNet-wearables_S06_1.hdf5\n",
      "file = S06_1.pkl\n",
      "\n",
      "Output: \n",
      "Error: \n",
      "Successfully processed 2022-07-12_15-08-08_streamLog_actionNet-wearables_S06_2.hdf5\n",
      "file = S06_2.pkl\n",
      "\n",
      "Output: \n",
      "Error: \n",
      "Successfully processed 2022-07-13_11-02-03_streamLog_actionNet-wearables_S07_1.hdf5\n",
      "file = S07_1.pkl\n",
      "\n",
      "Output: \n",
      "Error: \n",
      "Successfully processed 2022-07-14_09-59-00_streamLog_actionNet-wearables_S09_2.hdf5\n",
      "file = S09_2.pkl\n",
      "\n",
      "Output: \n",
      "Error: \n",
      "Successfully processed 2022-06-13_21-48-24_streamLog_actionNet-wearables_S02_2.hdf5\n",
      "file = S02_2.pkl\n",
      "\n",
      "Output: \n",
      "Error: \n",
      "Successfully processed 2022-07-13_14-15-26_streamLog_actionNet-wearables_S08_1.hdf5\n",
      "file = S08_1.pkl\n",
      "\n",
      "Output: \n",
      "Error: \n",
      "Successfully processed 2022-06-07_18-11-37_streamLog_actionNet-wearables_S00_2.hdf5\n",
      "file = S00_2.pkl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the source directory containing the .hdf5 files and the destination directory for the .pkl files\n",
    "source_dir = 'D:/ActionNetDataset/'\n",
    "dest_dir = 'D:/ActionNetDataset/saved_emg/'\n",
    "\n",
    "# List all .hdf5 files in the source directory\n",
    "hdf5_files = [f for f in os.listdir(source_dir) if f.endswith('.hdf5')]\n",
    "\n",
    "# Loop through each .hdf5 file and run the command\n",
    "for hdf5_file in hdf5_files:\n",
    "    source_filepath = os.path.join(source_dir, hdf5_file)\n",
    "    name_path = hdf5_file.replace('.hdf5', '.pkl')\n",
    "    dest = name_path.split('_')[-2] + '_' + name_path.split('_')[-1]\n",
    "    dest_filepath = os.path.join(dest_dir, dest)\n",
    "\n",
    "    \n",
    "    command = [\n",
    "        'python', 'extract_emg.py',\n",
    "        f'source_filepath={source_filepath}',\n",
    "        f'dest_filepath={dest_filepath}',\n",
    "    ]\n",
    "    \n",
    "    result = subprocess.run(command, capture_output=True, text=True)\n",
    "    \n",
    "    # Print the output and error\n",
    "    print('Output:', result.stdout)\n",
    "    print('Error:', result.stderr)\n",
    "    \n",
    "    # Check the return code\n",
    "    if result.returncode != 0:\n",
    "        print(f'Command failed with return code {result.returncode}')\n",
    "    else:\n",
    "        print(f'Successfully processed {hdf5_file}')\n",
    "    print(f'file = {dest}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time_s': 1655227278.399531,\n",
       " 'left_emg': [-0.9529871704833096,\n",
       "  -0.9274841832678671,\n",
       "  -0.8948020986880154,\n",
       "  -0.9402937530245367,\n",
       "  -0.9406966260114197,\n",
       "  -0.9354795261702438,\n",
       "  -0.918537193947152,\n",
       "  -0.9432085981480278],\n",
       " 'right_emg': [-0.9018822612033881,\n",
       "  -0.8795296668685978,\n",
       "  -0.556958018102873,\n",
       "  -0.5504120951277909,\n",
       "  -0.6194903485221537,\n",
       "  -0.7605260368916055,\n",
       "  -0.8749520737659409,\n",
       "  -0.9176174229005704]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.actionNet_emg_record import ActionNetVideoEmgRecord\n",
    "\n",
    "\n",
    "#try read emg\n",
    "\n",
    "file_path = \"D:/ActionNetDataset/saved_emg/S03_1.pkl\"\n",
    "df = pd.read_pickle(file_path)\n",
    "'''\n",
    "# Display the DataFrame\n",
    "#print(f\"durations = {df['end_time'] - df['start_time']}\")\n",
    "df.iloc[0]\n",
    "el = ActionNetVideoEmgRecord(df.iloc[0].description,df.iloc[0].description_class,df.iloc[0].emg_data[0])\n",
    "print(el.duration)\n",
    "print(el.description)\n",
    "print(el.label)\n",
    "print(el.get_emg(1))\n",
    "index = sorted(np.array(s04['index']) - 1)\n",
    "print(index)\n",
    "df_idx = df.iloc[index]\n",
    "video_list = []\n",
    "for i,(_,action) in enumerate(df_idx.iterrows()):\n",
    "    if i < 10:\n",
    "        descr = action['description']\n",
    "        label = action['description_class']\n",
    "        start = action['start_time']\n",
    "        end = action['end_time']\n",
    "        #print(action['description'])\n",
    "        #print(action['description_class'])\n",
    "        #print(action['start_time'])\n",
    "        #print(action['end_time'])\n",
    "        for el in action['emg_data']:\n",
    "            sample = ActionNetVideoEmgRecord(descr,label, el)\n",
    "            video_list.append(sample)\n",
    "        \n",
    "print(video_list[0])\n",
    "    '''\n",
    "df.emg_data[0][0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5, 10, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1795"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.loaders import ActionNetEmgDataset\n",
    "\n",
    "dataset = ActionNetEmgDataset('train', 10, 5, True, './action-net', 'D:/ActionNetDataset/saved_emg', 2)\n",
    "(el,l) = dataset.__getitem__(0)\n",
    "e = el.reshape(1, 5, 10, -1)  #(num_batch, num_clips, num_frames, num_features)\n",
    "print(e.shape)  # Controlla la forma dell'array\n",
    "len(dataset)\n",
    "#10,24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def check_images(frames_folder: str):\n",
    "    \"\"\"\n",
    "    Check if all images in the folder are valid and not corrupted.\n",
    "    \"\"\"\n",
    "    valid_images = 0\n",
    "    corrupted_images = 0\n",
    "\n",
    "    for filename in os.listdir(frames_folder):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            filepath = os.path.join(frames_folder, filename)\n",
    "            try:\n",
    "                with Image.open(filepath) as img:\n",
    "                    img.verify()  # Verifica che il file immagine sia valido\n",
    "                valid_images += 1\n",
    "            except (IOError, SyntaxError) as e:\n",
    "                print(f\"Corrupted image: {filepath}\")\n",
    "                corrupted_images += 1\n",
    "        if valid_images % 100 == 0:\n",
    "            print(f\"Total valid images: {valid_images}\")\n",
    "            print(f\"Total corrupted images: {corrupted_images}\")\n",
    "\n",
    "    print(f\"Total valid images: {valid_images}\")\n",
    "    print(f\"Total corrupted images: {corrupted_images}\")\n",
    "\n",
    "\n",
    "check_images('D:/ActionNetDataset/saved_RGB/camera1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.loaders import FeaturesDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = FeaturesDataset(\"./saved_features/saved_feat_I3D_10_dense_D1\",'test')\n",
    "#test_dataset = PACSDataset(domain='sketch', transform=dataset_transform)\n",
    "print(f\"Lunghezza = {len(train_dataset)}\\n\\n\")\n",
    "# Define the DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=4, drop_last=True)\n",
    "\n",
    "for i_val,(x, y) in (enumerate(train_loader)):\n",
    "    print(f\"{i_val}) x({x.shape}) = {x}  \\ny={y}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
