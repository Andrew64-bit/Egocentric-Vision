{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training VAE for RGB Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.loaders import FeaturesExtendedDataset\n",
    "\n",
    "from models import FC_VAE\n",
    "from train_vae import train, evaluate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50\n",
    "LR = 0.001\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-4\n",
    "STEP_SIZE = 15\n",
    "GAMMA = 0.1\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "    print(\"------ USING APPLE SILICON GPU ------\")\n",
    "\n",
    "features_file = \"saved_features/saved_feat_I3D_25_dense_D1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial model device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "482it [00:20, 23.39it/s]\n",
      "\u001b[32m2024-06-12 18:57:53\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 1, \tAverage Loss: , 0.00391683539447303\n",
      "482it [00:23, 20.88it/s]\n",
      "\u001b[32m2024-06-12 18:58:46\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 2, \tAverage Loss: , 0.003042558766707871\n",
      "482it [00:21, 22.12it/s]\n",
      "\u001b[32m2024-06-12 18:59:38\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 3, \tAverage Loss: , 0.0027793091276501793\n",
      "482it [00:22, 21.87it/s]\n",
      "\u001b[32m2024-06-12 19:00:32\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 4, \tAverage Loss: , 0.0026304349332288866\n",
      "482it [00:23, 20.20it/s]\n",
      "\u001b[32m2024-06-12 19:01:25\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 5, \tAverage Loss: , 0.002539346013711901\n",
      "482it [00:23, 20.10it/s]\n",
      "\u001b[32m2024-06-12 19:02:23\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 6, \tAverage Loss: , 0.0024693841361508487\n",
      "482it [00:25, 19.07it/s]\n",
      "\u001b[32m2024-06-12 19:03:21\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 7, \tAverage Loss: , 0.0024127200983557655\n",
      "482it [00:26, 18.09it/s]\n",
      "\u001b[32m2024-06-12 19:04:23\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 8, \tAverage Loss: , 0.00235726615305595\n",
      "482it [00:27, 17.43it/s]\n",
      "\u001b[32m2024-06-12 19:05:23\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 9, \tAverage Loss: , 0.0023171110245691546\n",
      "482it [00:29, 16.23it/s]\n",
      "\u001b[32m2024-06-12 19:06:27\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 10, \tAverage Loss: , 0.0022666770175850627\n",
      "482it [00:26, 17.92it/s]\n",
      "\u001b[32m2024-06-12 19:07:25\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 11, \tAverage Loss: , 0.0022363249174263055\n",
      "482it [00:28, 16.68it/s]\n",
      "\u001b[32m2024-06-12 19:08:26\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 12, \tAverage Loss: , 0.002214192264914714\n",
      "482it [00:27, 17.58it/s]\n",
      "\u001b[32m2024-06-12 19:09:23\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 13, \tAverage Loss: , 0.0021757515606696943\n",
      "482it [00:30, 16.04it/s]\n",
      "\u001b[32m2024-06-12 19:10:23\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 14, \tAverage Loss: , 0.002151648630630109\n",
      "482it [00:29, 16.48it/s]\n",
      "\u001b[32m2024-06-12 19:11:21\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 15, \tAverage Loss: , 0.002125725078952195\n",
      "482it [00:31, 15.19it/s]\n",
      "\u001b[32m2024-06-12 19:12:26\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 16, \tAverage Loss: , 0.002065301101931648\n",
      "482it [00:33, 14.49it/s]\n",
      "\u001b[32m2024-06-12 19:13:37\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 17, \tAverage Loss: , 0.0020202726032294473\n",
      "482it [00:32, 15.06it/s]\n",
      "\u001b[32m2024-06-12 19:14:42\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 18, \tAverage Loss: , 0.0020017491974490317\n",
      "482it [00:32, 15.05it/s]\n",
      "\u001b[32m2024-06-12 19:15:45\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 19, \tAverage Loss: , 0.0019906525993371176\n",
      "482it [00:32, 14.66it/s]\n",
      "\u001b[32m2024-06-12 19:16:48\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 20, \tAverage Loss: , 0.0019780090722505183\n",
      "482it [00:33, 14.37it/s]\n",
      "\u001b[32m2024-06-12 19:17:52\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 21, \tAverage Loss: , 0.001968437506625595\n",
      "482it [00:33, 14.44it/s]\n",
      "\u001b[32m2024-06-12 19:18:57\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 22, \tAverage Loss: , 0.0019603212939559825\n",
      "482it [00:32, 14.80it/s]\n",
      "\u001b[32m2024-06-12 19:20:00\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 23, \tAverage Loss: , 0.0019524361584393652\n",
      "482it [00:32, 14.72it/s]\n",
      "\u001b[32m2024-06-12 19:21:09\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 24, \tAverage Loss: , 0.0019449603880838861\n",
      "482it [00:31, 15.36it/s]\n",
      "\u001b[32m2024-06-12 19:22:08\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 25, \tAverage Loss: , 0.0019360120461967129\n",
      "482it [00:32, 14.94it/s]\n",
      "\u001b[32m2024-06-12 19:23:12\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 26, \tAverage Loss: , 0.0019298935323090074\n",
      "482it [00:32, 14.63it/s]\n",
      "\u001b[32m2024-06-12 19:24:16\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 27, \tAverage Loss: , 0.001923079029056718\n",
      "482it [00:32, 15.05it/s]\n",
      "\u001b[32m2024-06-12 19:25:19\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 28, \tAverage Loss: , 0.0019176294688298028\n",
      "482it [00:33, 14.32it/s]\n",
      "\u001b[32m2024-06-12 19:26:26\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 29, \tAverage Loss: , 0.001908833031269592\n",
      "482it [00:38, 12.64it/s]\n",
      "\u001b[32m2024-06-12 19:27:39\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 30, \tAverage Loss: , 0.0019033727368723268\n",
      "482it [00:35, 13.39it/s]\n",
      "\u001b[32m2024-06-12 19:28:52\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 31, \tAverage Loss: , 0.0018934368638983945\n",
      "482it [00:36, 13.38it/s]\n",
      "\u001b[32m2024-06-12 19:30:05\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 32, \tAverage Loss: , 0.0018874383330627841\n",
      "482it [00:36, 13.06it/s]\n",
      "\u001b[32m2024-06-12 19:31:15\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 33, \tAverage Loss: , 0.0018863910303321394\n",
      "482it [00:34, 13.98it/s]\n",
      "\u001b[32m2024-06-12 19:32:26\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 34, \tAverage Loss: , 0.0018847627664980112\n",
      "482it [00:38, 12.39it/s]\n",
      "\u001b[32m2024-06-12 19:33:37\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 35, \tAverage Loss: , 0.0018838941736297834\n",
      "482it [00:33, 14.34it/s]\n",
      "\u001b[32m2024-06-12 19:34:47\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 36, \tAverage Loss: , 0.0018828356192735743\n",
      "482it [00:33, 14.59it/s]\n",
      "\u001b[32m2024-06-12 19:35:51\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 37, \tAverage Loss: , 0.0018818864524809801\n",
      "482it [00:32, 14.73it/s]\n",
      "\u001b[32m2024-06-12 19:36:54\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 38, \tAverage Loss: , 0.001880434079128637\n",
      "482it [00:32, 14.61it/s]\n",
      "\u001b[32m2024-06-12 19:37:58\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 39, \tAverage Loss: , 0.001879888562497193\n",
      "482it [00:32, 14.63it/s]\n",
      "\u001b[32m2024-06-12 19:39:02\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 40, \tAverage Loss: , 0.0018797626863127253\n",
      "482it [00:32, 14.96it/s]\n",
      "\u001b[32m2024-06-12 19:40:05\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 41, \tAverage Loss: , 0.0018776760680074348\n",
      "482it [00:33, 14.32it/s]\n",
      "\u001b[32m2024-06-12 19:41:13\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 42, \tAverage Loss: , 0.0018784646070688158\n",
      "482it [00:33, 14.55it/s]\n",
      "\u001b[32m2024-06-12 19:42:20\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 43, \tAverage Loss: , 0.0018769667477573494\n",
      "482it [00:34, 13.96it/s]\n",
      "\u001b[32m2024-06-12 19:43:27\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 44, \tAverage Loss: , 0.0018762085517082293\n",
      "482it [00:32, 14.84it/s]\n",
      "\u001b[32m2024-06-12 19:44:33\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 45, \tAverage Loss: , 0.0018765121781152989\n",
      "482it [00:32, 14.75it/s]\n",
      "\u001b[32m2024-06-12 19:45:40\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 46, \tAverage Loss: , 0.0018736321722077915\n",
      "482it [00:32, 14.85it/s]\n",
      "\u001b[32m2024-06-12 19:46:44\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 47, \tAverage Loss: , 0.0018737179511797899\n",
      "482it [00:33, 14.55it/s]\n",
      "\u001b[32m2024-06-12 19:47:45\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 48, \tAverage Loss: , 0.0018728691385090817\n",
      "482it [00:32, 14.71it/s]\n",
      "\u001b[32m2024-06-12 19:48:50\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 49, \tAverage Loss: , 0.0018738199735985849\n",
      "482it [00:32, 14.78it/s]\n",
      "\u001b[32m2024-06-12 19:49:53\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 50, \tAverage Loss: , 0.0018742900811766978\n"
     ]
    }
   ],
   "source": [
    "train_dataset = FeaturesExtendedDataset(features_file,'train')\n",
    "train_loader_rgb = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, drop_last=True)\n",
    "\n",
    "\n",
    "model = FC_VAE(dim_input=1024, nz=64, n_hidden= 512,device='cpu')\n",
    "model.to(DEVICE)\n",
    "print(f'Initial model device: {model.device}')\n",
    "\n",
    "# Create Optimizer & Scheduler objects\n",
    "optimizer = Adam(model.parameters(), lr=LR, betas=(0.9, 0.98), eps=1e-9)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
    "\n",
    "train(model, optimizer, EPOCHS, DEVICE, train_loader_rgb, train_loader_rgb, BATCH_SIZE, scheduler)\n",
    "\n",
    "torch.save(model.state_dict(), f'./saved_models/VAE_RGB/final_VAE_RGB_epoch_{EPOCHS}.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7715it [00:38, 199.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2175it [00:14, 149.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0294\n"
     ]
    }
   ],
   "source": [
    "train_dataset = FeaturesExtendedDataset(features_file,'train')\n",
    "test_dataset = FeaturesExtendedDataset(features_file,'test')\n",
    "train_loader_rgb = DataLoader(train_dataset, batch_size=1, shuffle=False, num_workers=4, drop_last=True)\n",
    "test_loader_rgb = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=4, drop_last=True)\n",
    "\n",
    "model = FC_VAE(dim_input=1024, nz=64, n_hidden= 512, device='cpu')\n",
    "model.to(DEVICE)\n",
    "model.load_state_dict(torch.load(f'./saved_models/VAE_RGB/final_VAE_RGB_epoch_50.pth'))\n",
    "\n",
    "reconstructed, originals = evaluate(model, DEVICE, train_loader_rgb,train_loader_rgb)\n",
    "reconstructed2, originals2 = evaluate(model, DEVICE, test_loader_rgb,test_loader_rgb)\n",
    "\n",
    "#2024-06-12 18:20:00 LOG INFO \tEpoch, 30, \tAverage Loss: , 0.0020544183812745056\n",
    "#Test Loss: 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1617706  0.18080583 0.27730548 ... 0.26700526 0.4048736  0.2513174 ]\n",
      "[0.25173348 0.06175843 0.6073024  ... 0.6841187  0.21441153 0.4415941 ]\n",
      "Normalized Mean Squared Error: 0.0003446452901698649\n",
      "norm_original_data: 8.725092887878418\n",
      "MSE: 0.026236895471811295\n",
      "Mean Absolute Error (MAE): 0.11557242274284363\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "n = 16\n",
    "print(reconstructed2[n])\n",
    "print(originals2[n])\n",
    "mse_loss = nn.MSELoss()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# I due tensori tra cui calcolare la NMSE\n",
    "reconstructed_data = torch.tensor(reconstructed2[n])  # Tensor dei dati ricostruiti\n",
    "original_data = torch.tensor(originals2[n])       # Tensor dei dati originali\n",
    "\n",
    "# Calcola la norma del vettore dei dati effettivi\n",
    "norm_original_data = torch.norm(original_data)\n",
    "\n",
    "# Definisci la funzione di perdita MSE\n",
    "mse_loss = nn.MSELoss()\n",
    "\n",
    "# Calcola l'errore quadratico medio\n",
    "mse = mse_loss(reconstructed_data, original_data)\n",
    "\n",
    "# Calcola l'errore quadratico medio normalizzato\n",
    "nmse = mse / (norm_original_data ** 2)\n",
    "\n",
    "print(\"Normalized Mean Squared Error:\", nmse.item())\n",
    "print(\"norm_original_data:\", norm_original_data.item())\n",
    "\n",
    "\n",
    "\n",
    "# Calcola l'errore assoluto\n",
    "absolute_error = torch.abs(reconstructed_data - original_data)\n",
    "\n",
    "# Calcola il MAE\n",
    "mae = torch.mean(absolute_error)\n",
    "print(\"MSE:\", mse.item())\n",
    "print(\"Mean Absolute Error (MAE):\", mae.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training VAE for EMG Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.loaders import FeaturesExtendedEMGDataset\n",
    "\n",
    "from models import FC_VAE\n",
    "from train_vae import train_emg, evaluate_emg\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50\n",
    "LR = 0.001\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-4\n",
    "STEP_SIZE = 15\n",
    "GAMMA = 0.1\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "    print(\"------ USING APPLE SILICON GPU ------\")\n",
    "\n",
    "LSTM_features_file_train = \"saved_features/NEW_EMG_Emb_LSTM_25_dense_D1_train.pkl\"\n",
    "LSTM_features_file_test = \"saved_features/NEW_EMG_Emb_LSTM_25_dense_D1_test.pkl\"\n",
    "STAT_features_file_train = \"saved_features/EMG_Emb_Stat_25_dense_D1_train.pkl\"\n",
    "STAT_features_file_test = \"saved_features/EMG_Emb_Stat_25_dense_D1_test.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1024])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = FeaturesExtendedEMGDataset(LSTM_features_file_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, drop_last=True)\n",
    "\n",
    "for i in train_loader:\n",
    "    print(i[\"features\"].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'features': tensor([[-6.6190e-02,  5.6530e-02,  1.2611e-01,  ..., -2.8958e-01,\n",
      "          2.5173e-02, -9.0646e-02],\n",
      "        [-2.2526e-01,  1.1517e-01, -4.2411e-02,  ..., -1.9744e-01,\n",
      "          4.1075e-03,  1.7464e-02],\n",
      "        [-8.8189e-02,  6.5948e-02,  1.6635e-01,  ..., -2.5759e-01,\n",
      "         -1.8692e-03, -1.6630e-02],\n",
      "        ...,\n",
      "        [ 9.3071e-01,  7.3564e-02, -1.2945e-01,  ..., -2.4029e-01,\n",
      "          1.4612e-01,  2.9741e-02],\n",
      "        [ 8.8873e-01, -2.4171e-02, -1.5686e-01,  ..., -5.0851e-01,\n",
      "          2.2111e-01,  3.0519e-02],\n",
      "        [-3.5172e-01,  8.0837e-02, -1.6099e-02,  ...,  4.1486e-01,\n",
      "         -2.2982e-04, -2.5483e-01]]), 'labels': tensor([[ 2],\n",
      "        [ 2],\n",
      "        [ 2],\n",
      "        [ 2],\n",
      "        [ 2],\n",
      "        [ 1],\n",
      "        [ 1],\n",
      "        [ 1],\n",
      "        [ 1],\n",
      "        [ 1],\n",
      "        [10],\n",
      "        [10],\n",
      "        [10],\n",
      "        [10],\n",
      "        [10],\n",
      "        [19]])}\n"
     ]
    }
   ],
   "source": [
    "for (rgb_batch_idx, x) in enumerate(train_loader):\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial model device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "560it [00:25, 21.55it/s]\n",
      "\u001b[32m2024-06-12 20:03:06\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 1, \tAverage Loss: , 0.0059517194549861315\n",
      "560it [00:24, 23.25it/s]\n",
      "\u001b[32m2024-06-12 20:04:11\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 2, \tAverage Loss: , 0.004231555360304408\n",
      "560it [00:25, 22.28it/s]\n",
      "\u001b[32m2024-06-12 20:05:13\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 3, \tAverage Loss: , 0.00353982230862486\n",
      "560it [00:25, 22.33it/s]\n",
      "\u001b[32m2024-06-12 20:06:14\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 4, \tAverage Loss: , 0.003006360943850683\n",
      "560it [00:24, 23.20it/s]\n",
      "\u001b[32m2024-06-12 20:07:14\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 5, \tAverage Loss: , 0.0028009914945309553\n",
      "560it [00:25, 22.38it/s]\n",
      "\u001b[32m2024-06-12 20:08:15\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 6, \tAverage Loss: , 0.0025645678230662946\n",
      "560it [00:23, 23.66it/s]\n",
      "\u001b[32m2024-06-12 20:09:15\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 7, \tAverage Loss: , 0.0024349310696508224\n",
      "560it [00:25, 21.76it/s]\n",
      "\u001b[32m2024-06-12 20:10:20\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 8, \tAverage Loss: , 0.0022490288185918693\n",
      "560it [00:25, 21.60it/s]\n",
      "\u001b[32m2024-06-12 20:11:25\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 9, \tAverage Loss: , 0.002094579841512587\n",
      "560it [00:25, 22.21it/s]\n",
      "\u001b[32m2024-06-12 20:12:30\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 10, \tAverage Loss: , 0.0020053318693562475\n",
      "560it [00:26, 21.51it/s]\n",
      "\u001b[32m2024-06-12 20:13:34\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 11, \tAverage Loss: , 0.0019511843128513031\n",
      "560it [00:27, 20.35it/s]\n",
      "\u001b[32m2024-06-12 20:14:38\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 12, \tAverage Loss: , 0.001781469018761675\n",
      "560it [00:23, 23.70it/s]\n",
      "\u001b[32m2024-06-12 20:15:43\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 13, \tAverage Loss: , 0.0017666816515664774\n",
      "560it [00:25, 21.83it/s]\n",
      "\u001b[32m2024-06-12 20:16:51\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 14, \tAverage Loss: , 0.0016382448668866576\n",
      "560it [00:26, 21.40it/s]\n",
      "\u001b[32m2024-06-12 20:17:54\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 15, \tAverage Loss: , 0.0015748647942952479\n",
      "560it [00:26, 20.96it/s]\n",
      "\u001b[32m2024-06-12 20:18:57\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 16, \tAverage Loss: , 0.0012322714011233186\n",
      "560it [00:26, 21.47it/s]\n",
      "\u001b[32m2024-06-12 20:19:59\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 17, \tAverage Loss: , 0.0011076153874937079\n",
      "560it [00:27, 20.15it/s]\n",
      "\u001b[32m2024-06-12 20:21:01\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 18, \tAverage Loss: , 0.0010505188621471474\n",
      "560it [00:27, 20.01it/s]\n",
      "\u001b[32m2024-06-12 20:22:06\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 19, \tAverage Loss: , 0.0010077542397743408\n",
      "560it [00:27, 20.06it/s]\n",
      "\u001b[32m2024-06-12 20:23:09\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 20, \tAverage Loss: , 0.0009705129317766012\n",
      "560it [00:28, 19.79it/s]\n",
      "\u001b[32m2024-06-12 20:24:12\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 21, \tAverage Loss: , 0.0009404318140609746\n",
      "560it [00:29, 19.05it/s]\n",
      "\u001b[32m2024-06-12 20:25:19\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 22, \tAverage Loss: , 0.0009144468307232714\n",
      "560it [00:28, 19.77it/s]\n",
      "\u001b[32m2024-06-12 20:26:23\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 23, \tAverage Loss: , 0.0008931817945671036\n",
      "560it [00:29, 19.11it/s]\n",
      "\u001b[32m2024-06-12 20:27:29\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 24, \tAverage Loss: , 0.0008681302462527045\n",
      "560it [00:29, 19.21it/s]\n",
      "\u001b[32m2024-06-12 20:28:37\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 25, \tAverage Loss: , 0.0008498391723081183\n",
      "560it [00:28, 19.83it/s]\n",
      "\u001b[32m2024-06-12 20:29:50\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 26, \tAverage Loss: , 0.0008294188387505377\n",
      "560it [00:28, 19.64it/s]\n",
      "\u001b[32m2024-06-12 20:30:57\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 27, \tAverage Loss: , 0.0008116054880950926\n",
      "560it [00:27, 20.26it/s]\n",
      "\u001b[32m2024-06-12 20:32:00\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 28, \tAverage Loss: , 0.0007964804076005693\n",
      "560it [00:29, 19.23it/s]\n",
      "\u001b[32m2024-06-12 20:33:06\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 29, \tAverage Loss: , 0.0007797731264670961\n",
      "560it [00:27, 20.47it/s]\n",
      "\u001b[32m2024-06-12 20:34:13\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 30, \tAverage Loss: , 0.000768600553415769\n",
      "560it [00:28, 19.65it/s]\n",
      "\u001b[32m2024-06-12 20:35:18\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 31, \tAverage Loss: , 0.0007499961946984296\n",
      "560it [00:29, 19.30it/s]\n",
      "\u001b[32m2024-06-12 20:36:24\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 32, \tAverage Loss: , 0.0007333782683118298\n",
      "560it [00:29, 19.02it/s]\n",
      "\u001b[32m2024-06-12 20:37:35\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 33, \tAverage Loss: , 0.0007300782128306329\n",
      "560it [00:28, 19.83it/s]\n",
      "\u001b[32m2024-06-12 20:38:39\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 34, \tAverage Loss: , 0.0007252796741130834\n",
      "560it [00:28, 19.61it/s]\n",
      "\u001b[32m2024-06-12 20:39:42\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 35, \tAverage Loss: , 0.0007256689214973156\n",
      "560it [00:29, 18.92it/s]\n",
      "\u001b[32m2024-06-12 20:40:49\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 36, \tAverage Loss: , 0.0007202097773718546\n",
      "560it [00:34, 16.42it/s]\n",
      "\u001b[32m2024-06-12 20:42:00\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 37, \tAverage Loss: , 0.0007166224007023255\n",
      "560it [00:28, 19.43it/s]\n",
      "\u001b[32m2024-06-12 20:43:09\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 38, \tAverage Loss: , 0.0007164027294154863\n",
      "560it [00:28, 19.42it/s]\n",
      "\u001b[32m2024-06-12 20:44:16\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 39, \tAverage Loss: , 0.0007130743100387852\n",
      "560it [00:30, 18.66it/s]\n",
      "\u001b[32m2024-06-12 20:45:24\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 40, \tAverage Loss: , 0.0007105711479971189\n",
      "560it [00:29, 18.78it/s]\n",
      "\u001b[32m2024-06-12 20:46:33\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 41, \tAverage Loss: , 0.0007099469431508532\n",
      "560it [00:29, 19.07it/s]\n",
      "\u001b[32m2024-06-12 20:47:39\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 42, \tAverage Loss: , 0.0007069099936900871\n",
      "560it [00:29, 19.00it/s]\n",
      "\u001b[32m2024-06-12 20:48:48\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 43, \tAverage Loss: , 0.0007055507010587846\n",
      "560it [00:29, 18.92it/s]\n",
      "\u001b[32m2024-06-12 20:49:54\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 44, \tAverage Loss: , 0.0007025553629427902\n",
      "560it [00:29, 19.08it/s]\n",
      "\u001b[32m2024-06-12 20:51:00\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 45, \tAverage Loss: , 0.0007016097001976305\n",
      "560it [00:28, 19.34it/s]\n",
      "\u001b[32m2024-06-12 20:52:06\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 46, \tAverage Loss: , 0.000697389031153952\n",
      "560it [00:28, 19.63it/s]\n",
      "\u001b[32m2024-06-12 20:53:10\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 47, \tAverage Loss: , 0.0006973819875584046\n",
      "560it [00:29, 18.82it/s]\n",
      "\u001b[32m2024-06-12 20:54:17\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 48, \tAverage Loss: , 0.0006965172589733224\n",
      "560it [00:30, 18.07it/s]\n",
      "\u001b[32m2024-06-12 20:55:24\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 49, \tAverage Loss: , 0.0006982016030716509\n",
      "560it [00:30, 18.49it/s]\n",
      "\u001b[32m2024-06-12 20:56:32\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 50, \tAverage Loss: , 0.000695799753390176\n"
     ]
    }
   ],
   "source": [
    "model = FC_VAE(dim_input=1024, nz=64, n_hidden= 512,device='cpu')\n",
    "model.to(DEVICE)\n",
    "print(f'Initial model device: {model.device}')\n",
    "\n",
    "# Create Optimizer & Scheduler objects\n",
    "optimizer = Adam(model.parameters(), lr=LR, betas=(0.9, 0.98), eps=1e-9)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
    "\n",
    "train_emg(model, optimizer, EPOCHS, DEVICE, train_loader, train_loader, BATCH_SIZE, scheduler)\n",
    "\n",
    "torch.save(model.state_dict(), f'./saved_models/VAE_EMG/final_VAE_EMG_epoch_{EPOCHS}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8975it [00:51, 175.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8975it [00:51, 174.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0168\n"
     ]
    }
   ],
   "source": [
    "train_dataset = FeaturesExtendedEMGDataset(LSTM_features_file_train)\n",
    "test_dataset = FeaturesExtendedEMGDataset(LSTM_features_file_test)\n",
    "train_loader_emg = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=4, drop_last=True)\n",
    "test_loader_emg = DataLoader(test_dataset, batch_size=1, shuffle=True, num_workers=4, drop_last=True)\n",
    "\n",
    "model = FC_VAE(dim_input=1024, nz=64, n_hidden= 512, device='cpu')\n",
    "model.to(DEVICE)\n",
    "model.load_state_dict(torch.load(f'./saved_models/VAE_EMG/final_VAE_EMG_epoch_50.pth'))\n",
    "\n",
    "reconstructed, originals = evaluate_emg(model, DEVICE, train_loader_emg, train_loader_emg)\n",
    "reconstructed2, originals2 = evaluate_emg(model, DEVICE, test_loader_emg, test_loader_emg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0075567  -0.01152161  0.1278025  ... -0.09474144  0.02167922\n",
      " -0.07887158]\n",
      "[-0.03953028 -0.03217608  0.11024177 ... -0.09489374  0.04725005\n",
      " -0.10085487]\n",
      "Normalized Mean Squared Error: 0.0002937364624813199\n",
      "norm_original_data: 2.5818302631378174\n",
      "MSE: 0.0019580023363232613\n",
      "Mean Absolute Error (MAE): 0.031950294971466064\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "n = 16\n",
    "print(reconstructed2[n])\n",
    "print(originals2[n])\n",
    "mse_loss = nn.MSELoss()\n",
    "\n",
    "\n",
    "\n",
    "# I due tensori tra cui calcolare la NMSE\n",
    "reconstructed_data = torch.tensor(reconstructed2[n])  # Tensor dei dati ricostruiti\n",
    "original_data = torch.tensor(originals2[n])       # Tensor dei dati originali\n",
    "\n",
    "# Calcola la norma del vettore dei dati effettivi\n",
    "norm_original_data = torch.norm(original_data)\n",
    "\n",
    "# Definisci la funzione di perdita MSE\n",
    "mse_loss = nn.MSELoss()\n",
    "\n",
    "# Calcola l'errore quadratico medio\n",
    "mse = mse_loss(reconstructed_data, original_data)\n",
    "\n",
    "# Calcola l'errore quadratico medio normalizzato\n",
    "nmse = mse / (norm_original_data ** 2)\n",
    "\n",
    "print(\"Normalized Mean Squared Error:\", nmse.item())\n",
    "print(\"norm_original_data:\", norm_original_data.item())\n",
    "\n",
    "\n",
    "\n",
    "# Calcola l'errore assoluto\n",
    "absolute_error = torch.abs(reconstructed_data - original_data)\n",
    "\n",
    "# Calcola il MAE\n",
    "mae = torch.mean(absolute_error)\n",
    "print(\"MSE:\", mse.item())\n",
    "print(\"Mean Absolute Error (MAE):\", mae.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning Training [ RGB --> EMG ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.loaders import FeaturesExtendedDataset, FeaturesExtendedEMGDataset, ActionNetEmgRgbDataset\n",
    "from models import I3D\n",
    "from models import EMG_Feature_Extractor\n",
    "from utils.args import args\n",
    "from omegaconf import OmegaConf\n",
    "import tqdm\n",
    "import pickle\n",
    "\n",
    "\n",
    "from models import FC_VAE, LSTM_Emb_Classifier, EMG_Feature_Extractor\n",
    "from train_vae import train_tuning, evaluate_tuning\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "    print(\"------ USING APPLE SILICON GPU ------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-12 21:16:52\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m Loading Kinetics weights I3D\n",
      "\u001b[32m2024-06-12 21:16:52\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m  * Skipping Logits weight for 'logits.conv3d.weight'\n",
      "\u001b[32m2024-06-12 21:16:52\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m  * Skipping Logits weight for 'logits.conv3d.bias'\n",
      "c:\\Users\\iplov\\miniconda3\\envs\\aml_ego\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "186"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------- I3D ----------------------\n",
    "# CONFIGURATION FOR I3D\n",
    "conf_args = OmegaConf.load('configs/I3D_save_feat.yaml')\n",
    "args = OmegaConf.merge(args, conf_args)\n",
    "\n",
    "model_rgb = I3D(20, \"RGB\", args.models['RGB'], **args.models['RGB'].kwargs)\n",
    "train_augmentations, test_augmentations = model_rgb.get_augmentation('RGB')\n",
    "model_rgb.to(\"cpu\")\n",
    "\n",
    "# ---------------------- LSTM ----------------------\n",
    "# Parametri del modello\n",
    "input_dim = 16\n",
    "hidden_dim = 300\n",
    "embedding_dim = 256\n",
    "output_dim = 20  # Definisci il numero di classi\n",
    "\n",
    "model_emg = LSTM_Emb_Classifier(input_dim=input_dim, hidden_dim=hidden_dim, embedding_dim=embedding_dim, num_class=output_dim)\n",
    "model_emg.load_state_dict(torch.load(f'./saved_models/LSTM_Emb_Classifier/NEW_final_LSTM_Emb_25_epoch_10.pth'))\n",
    "model_emg.to(DEVICE)\n",
    "\n",
    "# ---------------------- DATASET ----------------------\n",
    "# DATASET 25 FRAMES PER CLIP AND 1 SAMPLE PER BATCH\n",
    "num_frames = 25\n",
    "num_clips = 1\n",
    "batch_size = 1\n",
    "dataset = ActionNetEmgRgbDataset('train', num_frames, num_clips, True, './action-net', 'action-net/saved_emg', \"D:/ActionNetDataset/saved_RGB/frames\", 2, train_augmentations)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4, drop_last=False)\n",
    "len(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURE EXTRACTION ACTION NET s04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186\n",
      "186\n"
     ]
    }
   ],
   "source": [
    "embeddings_rgb = []\n",
    "embeddings_emg = []\n",
    "\n",
    "\n",
    "model_rgb.train(False)\n",
    "with torch.no_grad():\n",
    "    for (idx, (emg,rgb,l)) in enumerate(data_loader):\n",
    "        e = emg.reshape(batch_size, num_clips, num_frames, -1)  #(num_batch, num_clips, num_frames, num_features)\n",
    "        # print(e)                  # torch.Size([1, 1, 25, 16])\n",
    "        emg_input = e[0].float() # torch.Size([25, 16])\n",
    "        emg_input = emg_input.to(DEVICE)\n",
    "\n",
    "        batch, _, height, width = rgb.shape\n",
    "        rgb_reshape = rgb.reshape(1, num_clips, num_frames, -1, height, width)\n",
    "        rgb_permute = rgb_reshape.permute(1, 0, 3, 2, 4, 5)\n",
    "        rgb_input = rgb_permute[0].to('cpu')    # CLIP\n",
    "        # print(rgb_permute.shape)   torch.Size([1, 1, 3 (RGB), 25, 224, 224])\n",
    "        # print(l)                   tensor([16])\n",
    "        # ---------------------- RGB EXTRACTION ----------------------\n",
    "        output_rgb, feat_rgb = model_rgb(rgb_input)\n",
    "        feat_rgb = feat_rgb[\"features\"]\n",
    "        sample_rgb = feat_rgb[0]      # torch.Size([1, 1024])\n",
    "        embeddings_rgb.append(sample_rgb)\n",
    "\n",
    "        # ---------------------- EMG EXTRACTION ----------------------\n",
    "        outputs_emg, feat_emg = model_emg(emg_input)\n",
    "        sample_emg = feat_emg[0]      # torch.Size([64])\n",
    "        embeddings_emg.append(sample_emg)\n",
    "\n",
    "        # ---------------------- EMG STAT EXTRACTION ----------------------\n",
    "        #embeddings = EMG_Feature_Extractor(emg_input[0])\n",
    "        #embeddings_emg.append(embeddings)\n",
    "\n",
    "print(len(embeddings_emg))\n",
    "print(len(embeddings_rgb))\n",
    "\n",
    "features_emg = \"saved_features/FINE_TUNING_emg_s04.pkl\"\n",
    "features_rgb = \"saved_features/FINE_TUNING_rgb_s04.pkl\"\n",
    "\n",
    "with open(features_rgb, 'wb') as f:\n",
    "    pickle.dump(embeddings_rgb, f)\n",
    "\n",
    "with open(features_emg, 'wb') as f:\n",
    "    pickle.dump(embeddings_emg, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100\n",
    "LR = 0.001\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-4\n",
    "STEP_SIZE = 50\n",
    "GAMMA = 0.1\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "    print(\"------ USING APPLE SILICON GPU ------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB dataset size: 19\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils.loaders import FeaturesTuningDataset\n",
    "\n",
    "rgb = FeaturesTuningDataset(\"./saved_features/FINE_TUNING_rgb_s04.pkl\")\n",
    "emg = FeaturesTuningDataset(\"./saved_features/FINE_TUNING_emg_s04.pkl\")\n",
    "print(f'RGB dataset size: {len(rgb)}')\n",
    "\n",
    "loader_rgb = DataLoader(rgb, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, drop_last=False, pin_memory=False)\n",
    "loader_emg = DataLoader(emg, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, drop_last=False, pin_memory=False)\n",
    "\n",
    "rgb_t = FeaturesTuningDataset(\"./saved_features/FINE_TUNING_rgb_s04_TEST.pkl\")\n",
    "emg_t = FeaturesTuningDataset(\"./saved_features/FINE_TUNING_emg_s04_TEST.pkl\")\n",
    "\n",
    "loader_rgb_t = DataLoader(rgb_t, batch_size=1, shuffle=False, num_workers=0, drop_last=False, pin_memory=False)\n",
    "loader_emg_t = DataLoader(emg_t, batch_size=1, shuffle=False, num_workers=0, drop_last=False, pin_memory=False)\n",
    "\n",
    "# print device loaders\n",
    "for (rgb_batch_idx, x) in enumerate(loader_rgb):\n",
    "    print(x.device)  # result --> cpu\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-12 21:57:02\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 1, \tAverage Loss: , 0.00885642478665845\n",
      "\u001b[32m2024-06-12 21:57:02\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 2, \tAverage Loss: , 0.006324561566791751\n",
      "\u001b[32m2024-06-12 21:57:02\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 3, \tAverage Loss: , 0.006045587604272772\n",
      "\u001b[32m2024-06-12 21:57:02\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 4, \tAverage Loss: , 0.005697414252526042\n",
      "\u001b[32m2024-06-12 21:57:03\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 5, \tAverage Loss: , 0.005372994505292313\n",
      "\u001b[32m2024-06-12 21:57:03\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 6, \tAverage Loss: , 0.004979134106013755\n",
      "\u001b[32m2024-06-12 21:57:04\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 7, \tAverage Loss: , 0.0046380482487041845\n",
      "\u001b[32m2024-06-12 21:57:04\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 8, \tAverage Loss: , 0.004268210196063261\n",
      "\u001b[32m2024-06-12 21:57:05\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 9, \tAverage Loss: , 0.004011058285620741\n",
      "\u001b[32m2024-06-12 21:57:05\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 10, \tAverage Loss: , 0.003699524021199481\n",
      "\u001b[32m2024-06-12 21:57:05\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 11, \tAverage Loss: , 0.0030873848326419566\n",
      "\u001b[32m2024-06-12 21:57:06\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 12, \tAverage Loss: , 0.002783575058195063\n",
      "\u001b[32m2024-06-12 21:57:06\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 13, \tAverage Loss: , 0.0023431101845662024\n",
      "\u001b[32m2024-06-12 21:57:06\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 14, \tAverage Loss: , 0.002108789059672166\n",
      "\u001b[32m2024-06-12 21:57:07\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 15, \tAverage Loss: , 0.001853129789444872\n",
      "\u001b[32m2024-06-12 21:57:07\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 16, \tAverage Loss: , 0.001657960714179684\n",
      "\u001b[32m2024-06-12 21:57:08\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 17, \tAverage Loss: , 0.001595614227963696\n",
      "\u001b[32m2024-06-12 21:57:08\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 18, \tAverage Loss: , 0.0014110550638923253\n",
      "\u001b[32m2024-06-12 21:57:08\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 19, \tAverage Loss: , 0.0013466986168747428\n",
      "\u001b[32m2024-06-12 21:57:09\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 20, \tAverage Loss: , 0.0013341018109878694\n",
      "\u001b[32m2024-06-12 21:57:09\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 21, \tAverage Loss: , 0.0012535300960404459\n",
      "\u001b[32m2024-06-12 21:57:10\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 22, \tAverage Loss: , 0.00122750165279616\n",
      "\u001b[32m2024-06-12 21:57:10\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 23, \tAverage Loss: , 0.001324141547560099\n",
      "\u001b[32m2024-06-12 21:57:11\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 24, \tAverage Loss: , 0.0012483856884169984\n",
      "\u001b[32m2024-06-12 21:57:11\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 25, \tAverage Loss: , 0.0012298079818719998\n",
      "\u001b[32m2024-06-12 21:57:11\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 26, \tAverage Loss: , 0.001132226731649346\n",
      "\u001b[32m2024-06-12 21:57:11\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 27, \tAverage Loss: , 0.0010644019705730236\n",
      "\u001b[32m2024-06-12 21:57:12\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 28, \tAverage Loss: , 0.0009755832606143402\n",
      "\u001b[32m2024-06-12 21:57:12\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 29, \tAverage Loss: , 0.000873448074509559\n",
      "\u001b[32m2024-06-12 21:57:12\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 30, \tAverage Loss: , 0.0008992112694117664\n",
      "\u001b[32m2024-06-12 21:57:13\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 31, \tAverage Loss: , 0.0009109137780879709\n",
      "\u001b[32m2024-06-12 21:57:13\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 32, \tAverage Loss: , 0.0008757877684812146\n",
      "\u001b[32m2024-06-12 21:57:14\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 33, \tAverage Loss: , 0.0008464710501191968\n",
      "\u001b[32m2024-06-12 21:57:14\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 34, \tAverage Loss: , 0.0008237070128829641\n",
      "\u001b[32m2024-06-12 21:57:14\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 35, \tAverage Loss: , 0.0007885998440377244\n",
      "\u001b[32m2024-06-12 21:57:14\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 36, \tAverage Loss: , 0.0008060688904317266\n",
      "\u001b[32m2024-06-12 21:57:15\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 37, \tAverage Loss: , 0.0007325805543752557\n",
      "\u001b[32m2024-06-12 21:57:16\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 38, \tAverage Loss: , 0.0007217998857165433\n",
      "\u001b[32m2024-06-12 21:57:16\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 39, \tAverage Loss: , 0.0006847995034397834\n",
      "\u001b[32m2024-06-12 21:57:17\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 40, \tAverage Loss: , 0.0006664534481718543\n",
      "\u001b[32m2024-06-12 21:57:17\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 41, \tAverage Loss: , 0.0006964594662845643\n",
      "\u001b[32m2024-06-12 21:57:18\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 42, \tAverage Loss: , 0.0007553247004662725\n",
      "\u001b[32m2024-06-12 21:57:18\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 43, \tAverage Loss: , 0.0007428006945040331\n",
      "\u001b[32m2024-06-12 21:57:18\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 44, \tAverage Loss: , 0.0007806464868322523\n",
      "\u001b[32m2024-06-12 21:57:19\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 45, \tAverage Loss: , 0.0007270321167941967\n",
      "\u001b[32m2024-06-12 21:57:19\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 46, \tAverage Loss: , 0.0005927145843584599\n",
      "\u001b[32m2024-06-12 21:57:20\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 47, \tAverage Loss: , 0.0005694965280285528\n",
      "\u001b[32m2024-06-12 21:57:20\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 48, \tAverage Loss: , 0.0005426472304283049\n",
      "\u001b[32m2024-06-12 21:57:20\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 49, \tAverage Loss: , 0.0005326165754178709\n",
      "\u001b[32m2024-06-12 21:57:21\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 50, \tAverage Loss: , 0.0005425931541884148\n",
      "\u001b[32m2024-06-12 21:57:21\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 51, \tAverage Loss: , 0.0004779514115811749\n",
      "\u001b[32m2024-06-12 21:57:22\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 52, \tAverage Loss: , 0.00043279634006797676\n",
      "\u001b[32m2024-06-12 21:57:22\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 53, \tAverage Loss: , 0.00039028650710613215\n",
      "\u001b[32m2024-06-12 21:57:22\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 54, \tAverage Loss: , 0.0003778727636513808\n",
      "\u001b[32m2024-06-12 21:57:23\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 55, \tAverage Loss: , 0.0003713824579873207\n",
      "\u001b[32m2024-06-12 21:57:23\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 56, \tAverage Loss: , 0.0003612628629939123\n",
      "\u001b[32m2024-06-12 21:57:24\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 57, \tAverage Loss: , 0.0003589061608098828\n",
      "\u001b[32m2024-06-12 21:57:24\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 58, \tAverage Loss: , 0.00035809565451927483\n",
      "\u001b[32m2024-06-12 21:57:25\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 59, \tAverage Loss: , 0.0003552479746841445\n",
      "\u001b[32m2024-06-12 21:57:25\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 60, \tAverage Loss: , 0.00035426864616800395\n",
      "\u001b[32m2024-06-12 21:57:26\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 61, \tAverage Loss: , 0.0003561370838063092\n",
      "\u001b[32m2024-06-12 21:57:26\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 62, \tAverage Loss: , 0.0003451926237506665\n",
      "\u001b[32m2024-06-12 21:57:27\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 63, \tAverage Loss: , 0.00034591179990622385\n",
      "\u001b[32m2024-06-12 21:57:27\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 64, \tAverage Loss: , 0.00034587198570079636\n",
      "\u001b[32m2024-06-12 21:57:28\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 65, \tAverage Loss: , 0.00034109178093124433\n",
      "\u001b[32m2024-06-12 21:57:28\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 66, \tAverage Loss: , 0.0003458130076151892\n",
      "\u001b[32m2024-06-12 21:57:28\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 67, \tAverage Loss: , 0.0003361657039601017\n",
      "\u001b[32m2024-06-12 21:57:29\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 68, \tAverage Loss: , 0.0003377417259881358\n",
      "\u001b[32m2024-06-12 21:57:29\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 69, \tAverage Loss: , 0.00033177987246414307\n",
      "\u001b[32m2024-06-12 21:57:30\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 70, \tAverage Loss: , 0.0003315630237921141\n",
      "\u001b[32m2024-06-12 21:57:30\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 71, \tAverage Loss: , 0.0003304116684872001\n",
      "\u001b[32m2024-06-12 21:57:31\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 72, \tAverage Loss: , 0.000326859845286394\n",
      "\u001b[32m2024-06-12 21:57:31\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 73, \tAverage Loss: , 0.00032396777433777146\n",
      "\u001b[32m2024-06-12 21:57:31\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 74, \tAverage Loss: , 0.0003280384966770229\n",
      "\u001b[32m2024-06-12 21:57:32\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 75, \tAverage Loss: , 0.0003198512465380852\n",
      "\u001b[32m2024-06-12 21:57:32\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 76, \tAverage Loss: , 0.0003176762594111179\n",
      "\u001b[32m2024-06-12 21:57:33\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 77, \tAverage Loss: , 0.0003173119717261712\n",
      "\u001b[32m2024-06-12 21:57:33\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 78, \tAverage Loss: , 0.00031839851131239396\n",
      "\u001b[32m2024-06-12 21:57:33\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 79, \tAverage Loss: , 0.00032079770062409807\n",
      "\u001b[32m2024-06-12 21:57:34\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 80, \tAverage Loss: , 0.00031485981493129987\n",
      "\u001b[32m2024-06-12 21:57:34\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 81, \tAverage Loss: , 0.0003114526493432508\n",
      "\u001b[32m2024-06-12 21:57:34\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 82, \tAverage Loss: , 0.0003094761877119626\n",
      "\u001b[32m2024-06-12 21:57:35\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 83, \tAverage Loss: , 0.0003088948076104068\n",
      "\u001b[32m2024-06-12 21:57:35\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 84, \tAverage Loss: , 0.0003075728818657808\n",
      "\u001b[32m2024-06-12 21:57:36\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 85, \tAverage Loss: , 0.000302008454706414\n",
      "\u001b[32m2024-06-12 21:57:36\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 86, \tAverage Loss: , 0.0003099051667628704\n",
      "\u001b[32m2024-06-12 21:57:36\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 87, \tAverage Loss: , 0.00030251937145790595\n",
      "\u001b[32m2024-06-12 21:57:37\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 88, \tAverage Loss: , 0.000306843348715285\n",
      "\u001b[32m2024-06-12 21:57:37\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 89, \tAverage Loss: , 0.00030401827875307805\n",
      "\u001b[32m2024-06-12 21:57:38\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 90, \tAverage Loss: , 0.0003041902172381842\n",
      "\u001b[32m2024-06-12 21:57:38\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 91, \tAverage Loss: , 0.0003012529758217914\n",
      "\u001b[32m2024-06-12 21:57:38\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 92, \tAverage Loss: , 0.00029629058586909775\n",
      "\u001b[32m2024-06-12 21:57:39\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 93, \tAverage Loss: , 0.000296869524886874\n",
      "\u001b[32m2024-06-12 21:57:39\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 94, \tAverage Loss: , 0.0002988419763079781\n",
      "\u001b[32m2024-06-12 21:57:39\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 95, \tAverage Loss: , 0.0002915270418849435\n",
      "\u001b[32m2024-06-12 21:57:40\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 96, \tAverage Loss: , 0.00028923358728537676\n",
      "\u001b[32m2024-06-12 21:57:40\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 97, \tAverage Loss: , 0.0002866605930400758\n",
      "\u001b[32m2024-06-12 21:57:41\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 98, \tAverage Loss: , 0.000284965655075873\n",
      "\u001b[32m2024-06-12 21:57:41\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 99, \tAverage Loss: , 0.00028628719784054823\n",
      "\u001b[32m2024-06-12 21:57:41\u001b[0m \u001b[34mLOG\u001b[0m \u001b[1;30mINFO\u001b[0m \tEpoch, 100, \tAverage Loss: , 0.00029229084198463664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0744\n"
     ]
    }
   ],
   "source": [
    "from train_vae import loss_function\n",
    "from utils.logger import setup_logger\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "from train_vae import train_tuning, evaluate_tuning\n",
    "\n",
    "# LSTM EMG dimension is 64 \n",
    "# STAT EMG dimension is 112\n",
    "model_finetune = FC_VAE(dim_input=1024, nz=64, dim_output=1024, n_hidden=512, device=DEVICE)\n",
    "model_finetune.to(DEVICE)\n",
    "\n",
    "# Carica i pesi del modello RGB per l'encoder\n",
    "checkpoint_rgb = torch.load('./saved_models/VAE_RGB/final_VAE_RGB_epoch_50.pth', map_location=DEVICE)\n",
    "# Rimuovi il prefisso 'encoder.' dalle chiavi dello state_dict\n",
    "checkpoint_rgb = {k.replace('encoder.', ''): v for k, v in checkpoint_rgb.items() if 'encoder' in k}\n",
    "model_finetune.encoder.load_state_dict(checkpoint_rgb)\n",
    "\n",
    "# Carica i pesi del modello EMG per il decoder\n",
    "checkpoint_emg = torch.load('./saved_models/VAE_EMG/final_VAE_EMG_epoch_50.pth', map_location=DEVICE)\n",
    "checkpoint_emg = {k.replace('decoder.', ''): v for k, v in checkpoint_emg.items() if 'decoder' in k}\n",
    "model_finetune.decoder.load_state_dict(checkpoint_emg)\n",
    "\n",
    "# Create Optimizer & Scheduler objects\n",
    "optimizer = Adam(model_finetune.parameters(), lr=LR, betas=(0.9, 0.98), eps=1e-9)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
    "\n",
    "train_tuning(model_finetune, optimizer, EPOCHS, DEVICE, loader_rgb, loader_emg, BATCH_SIZE, scheduler)\n",
    "evaluate_tuning(model_finetune, DEVICE, loader_rgb_t, loader_emg_t)\n",
    "\n",
    "torch.save(model_finetune.state_dict(), f'./saved_models/VAE_Fine_Tuninng/VAE_RGB_to_EMG_LSTM_epoch_{EPOCHS}.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
