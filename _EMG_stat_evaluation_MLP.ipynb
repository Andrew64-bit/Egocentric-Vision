{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EVALUATION Statistichs with MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreavannozzi/GithubProjects/Multimodal-Egocentric-Action-Recognition/env/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/andreavannozzi/GithubProjects/Multimodal-Egocentric-Action-Recognition/env/lib/python3.8/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <0EB69795-4559-3C98-9EA1-35B6A988BB99> /Users/andreavannozzi/GithubProjects/Multimodal-Egocentric-Action-Recognition/env/lib/python3.8/site-packages/torchvision/image.so\n",
      "  Expected in:     <E4E2FFCA-031E-3974-A7B0-45408D7F4956> /Users/andreavannozzi/GithubProjects/Multimodal-Egocentric-Action-Recognition/env/lib/python3.8/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from models import LSTM_Emb_Classifier, EMG_Feature_Extractor\n",
    "from utils.loaders import ActionNetEmgDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.logger import logger\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "from utils.loaders import FeaturesExtendedEMGDataset\n",
    "from models import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from models import LSTM_Emb_Classifier, EMG_Feature_Extractor\n",
    "from utils.loaders import ActionNetEmgDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.logger import logger\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "from utils.loaders import FeaturesExtendedEMGDataset\n",
    "from models import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-08 18:30:15 LOG INFO ------ USING APPLE SILICON GPU ------\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "LR = 0.008\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-4\n",
    "STEP_SIZE = 20\n",
    "GAMMA = 0.1\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = 'mps'\n",
    "    logger.info(\"------ USING APPLE SILICON GPU ------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-08 18:32:29 LOG INFO Model: MLP(\n",
      "  (classifier): Sequential(\n",
      "    (0): ReLU()\n",
      "    (1): Linear(in_features=16, out_features=512, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=512, out_features=20, bias=True)\n",
      "  )\n",
      ")\n",
      "2024-06-08 18:32:29 LOG INFO len train_dataset: 8975\n",
      "2024-06-08 18:32:29 LOG INFO len train_loader: 280\n"
     ]
    }
   ],
   "source": [
    "model = MLP(clip_feature_dim=16, num_class=20)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
    "\n",
    "filepath = \"saved_features/saved_feat_EMG_statistichs_25_dense_D1_train.pkl\"\n",
    "filepath2 = \"saved_features/saved_feat_EMG_statistichs_25_dense_D1_test.pkl\"\n",
    "\n",
    "train_dataset = FeaturesExtendedEMGDataset(filepath)\n",
    "loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True, drop_last=True) # Inserisci il dataloader per il training\n",
    "\n",
    "test_dataset = FeaturesExtendedEMGDataset(filepath2)\n",
    "loader2 = DataLoader(test_dataset, batch_size=1, shuffle=True, num_workers=4, pin_memory=True, drop_last=True)\n",
    "\n",
    "logger.info(f\"Model: {model}\")\n",
    "logger.info(f\"len train_dataset: {len(train_dataset)}\")\n",
    "logger.info(f\"len train_loader: {len(loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        epoch_loss = [0.0, 0]\n",
    "        for i_idx , x in tqdm(enumerate(train_loader1)):\n",
    "            print(x.size())\n",
    "            x = x.reshape(BATCH_SIZE, 5, 25, -1)\n",
    "            x = x.permute(1, 0, 2, 3)\n",
    "            y = y.to(DEVICE)\n",
    "            #logger.info(f\"X: {x[0][0]}\")\n",
    "            # Category Loss\n",
    "            #logger.info(f\"X: {x.size()}\")\n",
    "            for i in range(5):\n",
    "                x_t = x[i].float().to(DEVICE)\n",
    "                outputs, embeddings = model(x_t)\n",
    "                # Log details about the outputs\n",
    "                #logger.info(f\"Output type: {cls_o.logits.shape}\")\n",
    "                loss = criterion(outputs, y.long())\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                epoch_loss[0] += loss.item()\n",
    "                epoch_loss[1] += x.size(0)\n",
    "\n",
    "                if (i_val + 1) % (len(train_loader1) // 5) == 0:\n",
    "                    logger.info(\"[{}/{}]\".format(i + 1, len(train_loader1)))\n",
    "            \n",
    "        scheduler.step()\n",
    "        logger.info(f'[EPOCH {epoch+1}] Avg. Loss: {epoch_loss[0] / epoch_loss[1]}')\n",
    "\n",
    "\n",
    "        #save checkpoint in a file\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            train_accuracy = evaluate(model, train_loader1, DEVICE)\n",
    "            val_accuracy = evaluate(model, test_loader1, DEVICE)\n",
    "            logger.info(f'[EPOCH {epoch+1}] Train Accuracy: {train_accuracy}')\n",
    "            logger.info(f'[EPOCH {epoch+1}] Val Accuracy: {val_accuracy}')\n",
    "            torch.save(model.state_dict(), f'./saved_models/LSTM_Emb_Classifier/final_LSTM_Emb_epoch_{epoch+1}.pth')\n",
    "        if (epoch+1) % STEP_SIZE == 0:\n",
    "            logger.info(f'Current LR: {scheduler.get_last_lr()}')\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
